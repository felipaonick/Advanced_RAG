{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd9a636",
   "metadata": {},
   "source": [
    "# üìä **RAGAS ‚Äì Valutazione delle Pipeline RAG con LangChain**\n",
    "\n",
    "## üß† Cos'√® RAGAS?\n",
    "\n",
    "**RAGAS** (*Retrieval-Augmented Generation Assessment Suite*) √® un framework open-source per valutare la **qualit√† delle pipeline RAG** usando modelli LLM e metriche standardizzate.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Obiettivo\n",
    "\n",
    "* Valutare se una pipeline RAG:\n",
    "\n",
    "  * Recupera i documenti giusti\n",
    "  * Genera risposte accurate e pertinenti\n",
    "  * Si basa sul contesto effettivamente fornito\n",
    "\n",
    "---\n",
    "\n",
    "## üìè **Metriche Principali**\n",
    "\n",
    "| üìà Metrica               | Descrizione                                                                                                         |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Faithfulness**         | Quanto la risposta √® *fattualmente coerente* con il contesto. Punteggi alti = poche allucinazioni.                  |\n",
    "| **Answer Relevance**     | Quanto la risposta √® pertinente rispetto alla domanda originale. Basata su similarit√† semantica domanda ‚Üî risposta. |\n",
    "| **Context Precision**    | Misura se i chunk rilevanti (gold) sono posizionati in alto tra i documenti recuperati.                             |\n",
    "| **Context Recall**       | Quanto il contesto recuperato copre tutti gli elementi presenti nella risposta generata.                            |\n",
    "| **Contextual Relevance** | Quanto i documenti recuperati sono rilevanti rispetto alla domanda.                                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Setup del Dataset\n",
    "\n",
    "### üì• Caricamento Documenti\n",
    "\n",
    "üß© Risultato: 33 chunk creati da 3 documenti `.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3051ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\"./data\", glob=\"**/*.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c4f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0efeb5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\food.txt'}, page_content='margherita pizza; $12; classic with tomato, mozzarella, and basil; main dish\\n\\nspaghetti carbonara; $15; creamy pasta with pancetta and parmesan; main dish\\n\\nbruschetta; $8; toasted bread with tomato, garlic, and olive oil; appetizer\\n\\ncaprese salad; $10; fresh tomatoes, mozzarella, and basil; salad\\n\\nlasagna; $14; layered pasta with meat sauce and cheese; main dish\\n\\ntiramisu; $9; coffee-flavored italian dessert; dessert\\n\\ngelato; $7; traditional italian ice cream; dessert')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759da399",
   "metadata": {},
   "source": [
    "Per far funzionare RAGAS, abbiamo bisogno nei metadati di una chiave speciale chiamata filename. Ragas si aspetta una chiave file_name nei metadata dei Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b3cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in chunks:\n",
    "    document.metadata['file_name'] = document.metadata['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bf365",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Generazione del Set di Test\n",
    "\n",
    "\n",
    "üìå Il set di test √® costituito da:\n",
    "\n",
    "* ‚ùì Una lista di **domande**\n",
    "* ‚úÖ La **ground-truth answer** (attesa)\n",
    "* üìÑ Chunk testuali da cui generare risposte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8479a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   0%|          | 0/22 [00:00<?, ?it/s]       Node 34243639-3002-417a-b5b1-af2ced114507 does not have a summary. Skipping filtering.\n",
      "Node 45540005-2f3d-4d2c-a8c1-23b64ac0d7c7 does not have a summary. Skipping filtering.\n",
      "Node 9d750f6f-1077-40a1-8e6c-82bbb7bd6503 does not have a summary. Skipping filtering.\n",
      "Node 5904f5e9-53fa-4126-a1dc-2234b5e94623 does not have a summary. Skipping filtering.\n",
      "Node 34fb689f-1e17-4aca-a463-0ea061dd590b does not have a summary. Skipping filtering.\n",
      "Node 71e8b7c4-1a16-4c41-b192-5d519aa32f21 does not have a summary. Skipping filtering.\n",
      "Node 0d5b7f1f-af99-4b33-a8c2-766ae78b0618 does not have a summary. Skipping filtering.\n",
      "Node fc1420c2-cfca-4594-9adf-bf302e40022d does not have a summary. Skipping filtering.\n",
      "Node 3500ae0e-772d-4845-9a3f-b21b30b2553f does not have a summary. Skipping filtering.\n",
      "Node 19862a1b-fd38-4472-ae27-8ec03f7ef831 does not have a summary. Skipping filtering.\n",
      "Node b8e0ee70-54c2-448c-ae2a-532f0c6ceca3 does not have a summary. Skipping filtering.\n",
      "Node 81174d84-6338-4010-8d5d-d8b1c2410763 does not have a summary. Skipping filtering.\n",
      "Node 5e542f73-0282-45dc-8e9a-6edaf0fc6dbc does not have a summary. Skipping filtering.\n",
      "Node 4b7e3024-bafb-4a5c-a48f-e73a161ea635 does not have a summary. Skipping filtering.\n",
      "Node 44f75298-9a40-4dc2-93d2-017f46ffe924 does not have a summary. Skipping filtering.\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.32it/s]                                           \n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.96s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:02<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    chunks,\n",
    "    testset_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5789e0e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí∏ Attenzione ai Costi\n",
    "\n",
    "| Modello         | Costo Stimato            |\n",
    "| --------------- | ------------------------ |\n",
    "| `gpt-3.5-turbo` | ‚úÖ Economico              |\n",
    "| `gpt-4`         | ‚ùå Fino a 10x pi√π costoso |\n",
    "\n",
    "üìå *Ogni elemento del testset richiede almeno 2 chiamate LLM (domanda + risposta).*\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Esportazione\n",
    "\n",
    "Una volta generato il set, √® possibile esportarlo:\n",
    "\n",
    "```python\n",
    "testset.to_pandas().to_csv(\"qa_testset.csv\", index=False)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cc540ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you describe the characteristics and compo...</td>\n",
       "      <td>[margherita pizza; $12; classic with tomato, m...</td>\n",
       "      <td>Bruschetta is an appetizer that consists of to...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is prosecco and how much does it cost?</td>\n",
       "      <td>[risotto milanese; $16; creamy saffron-infused...</td>\n",
       "      <td>Prosecco is an Italian sparkling white wine th...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is espresso and how much does it cost?</td>\n",
       "      <td>[calamari; $12; fried squid rings with marinar...</td>\n",
       "      <td>Espresso is a strong Italian coffee that costs...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the characteristics of calamari and h...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ncalamari; $12; fried squid rings w...</td>\n",
       "      <td>Calamari, priced at $12, is described as fried...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the price of calamari and gnocchi?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ncalamari; $12; fried squid rings w...</td>\n",
       "      <td>The price of calamari is $12, and the price of...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wut is the price of calamari and how does it c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ncalamari; $12; fried squid rings w...</td>\n",
       "      <td>The price of calamari is $12, while frutti di ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What unique dishes from Sicily did Chef Amico ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nAs he grew, so did his desire to e...</td>\n",
       "      <td>While exploring Italian cuisine, Chef Amico le...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What did Chef Amico learn about Italian cuisin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIn the charming streets of Palermo...</td>\n",
       "      <td>While traveling through Italy, Chef Amico lear...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How did Amico's upbringing in Palermo influenc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIn the heart of the old quarter of...</td>\n",
       "      <td>Amico's upbringing in Palermo, where he was ra...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Can you describe the characteristics and compo...   \n",
       "1        What is prosecco and how much does it cost?   \n",
       "2        What is espresso and how much does it cost?   \n",
       "3  What are the characteristics of calamari and h...   \n",
       "4         what is the price of calamari and gnocchi?   \n",
       "5  Wut is the price of calamari and how does it c...   \n",
       "6  What unique dishes from Sicily did Chef Amico ...   \n",
       "7  What did Chef Amico learn about Italian cuisin...   \n",
       "8  How did Amico's upbringing in Palermo influenc...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [margherita pizza; $12; classic with tomato, m...   \n",
       "1  [risotto milanese; $16; creamy saffron-infused...   \n",
       "2  [calamari; $12; fried squid rings with marinar...   \n",
       "3  [<1-hop>\\n\\ncalamari; $12; fried squid rings w...   \n",
       "4  [<1-hop>\\n\\ncalamari; $12; fried squid rings w...   \n",
       "5  [<1-hop>\\n\\ncalamari; $12; fried squid rings w...   \n",
       "6  [<1-hop>\\n\\nAs he grew, so did his desire to e...   \n",
       "7  [<1-hop>\\n\\nIn the charming streets of Palermo...   \n",
       "8  [<1-hop>\\n\\nIn the heart of the old quarter of...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Bruschetta is an appetizer that consists of to...   \n",
       "1  Prosecco is an Italian sparkling white wine th...   \n",
       "2  Espresso is a strong Italian coffee that costs...   \n",
       "3  Calamari, priced at $12, is described as fried...   \n",
       "4  The price of calamari is $12, and the price of...   \n",
       "5  The price of calamari is $12, while frutti di ...   \n",
       "6  While exploring Italian cuisine, Chef Amico le...   \n",
       "7  While traveling through Italy, Chef Amico lear...   \n",
       "8  Amico's upbringing in Palermo, where he was ra...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  multi_hop_abstract_query_synthesizer  \n",
       "4  multi_hop_abstract_query_synthesizer  \n",
       "5  multi_hop_abstract_query_synthesizer  \n",
       "6  multi_hop_specific_query_synthesizer  \n",
       "7  multi_hop_specific_query_synthesizer  \n",
       "8  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aae1ca",
   "metadata": {},
   "source": [
    "Per via dei costi di generazione usiamo un datset gi√† ampliato dove abbiamo molteplici domande ed il ground truth per la domanda che verr√† utilizzato per effettuare la nostra valutazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e2273a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîú Prossimo Modulo\n",
    "\n",
    "‚û°Ô∏è **Valutazione automatica delle risposte** con `evaluate()` usando le metriche viste sopra, il set generato e la pipeline RAG.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Riepilogo Visivo\n",
    "\n",
    "```\n",
    "Documenti TXT\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "Chunking con metadati [\"filename\"]\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "Testset Generator ‚Üí (Domanda, Risposta Attesa)\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "Valutazione con LLM + metriche RAGAS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
