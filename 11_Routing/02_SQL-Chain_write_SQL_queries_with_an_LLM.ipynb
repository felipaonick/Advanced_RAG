{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18253ce7",
   "metadata": {},
   "source": [
    "# üß† Routing e Query su Database (LangChain + Postgres)\n",
    "\n",
    "## üì¶ Obiettivi\n",
    "\n",
    "* Integrazione del **vector store** con **PostgreSQL**.\n",
    "* Costruzione di una **catena ibrida** che combina RAG con query SQL.\n",
    "* Introduzione al **routing** (in arrivo nel prossimo video).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup Iniziale\n",
    "\n",
    "### ‚ñ∂Ô∏è Avvio del database\n",
    "\n",
    "Assicurati che Postgres sia attivo:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "### üì¶ Database Postgres per due usi:\n",
    "\n",
    "* Come **vector store** (via PGVector)\n",
    "* Come **tabella SQL** per query strutturate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398c7cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a8c0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Ingestione dei Documenti nel Vector Store\n",
    "\n",
    "### üßπ Pulizia tabelle precedenti\n",
    "\n",
    "```bash\n",
    "python clear_tables.py\n",
    "```\n",
    "\n",
    "### üóÇÔ∏è File utilizzati:\n",
    "\n",
    "* `founder.txt`\n",
    "* `restaurant.txt`\n",
    "\n",
    "> üî• Evitiamo `food.txt` perch√© contiene **dati tabellari** che non sono adatti al vector store.\n",
    "\n",
    "### üß± Creazione del vector store:\n",
    "\n",
    "```python\n",
    "vectorstore = PGVector(\n",
    "    collection_name=\"vector_db\",\n",
    "    connection_string=db_url,\n",
    "    embedding=my_embeddings,\n",
    ")\n",
    "```\n",
    "\n",
    "### üìñ Chunking & Inserimento\n",
    "\n",
    "* Carichiamo i file `.txt`\n",
    "* Splittiamo i contenuti in chunk\n",
    "* Li aggiungiamo al vector store\n",
    "* Convertiamo il tutto in un **retriever**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae1d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Local\\Temp\\ipykernel_9488\\2757803120.py:5: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = PGVector(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/restaurant.txt'}, page_content=\"In the charming streets of Palermo, tucked away in a quaint alley, stood Chef Amico, a restaurant that was more than a mere eatery√¢‚Ç¨‚Äùit was a slice of Sicilian heaven. Founded by Amico, a chef whose name was synonymous with passion and creativity, the restaurant was a mosaic of his life√¢‚Ç¨‚Ñ¢s journey through the flavors of Italy.\\n\\nChef Amico√¢‚Ç¨‚Ñ¢s doors opened to a world where the aromas of garlic and olive oil were as welcoming as a warm embrace. The walls, adorned with photos of Amico√¢‚Ç¨‚Ñ¢s travels and family recipes, spoke of a rich culinary heritage. The chatter and laughter of patrons filled the air, creating a symphony as delightful as the dishes served.\\n\\nOne evening, as the sun cast a golden glow over the city, a renowned food critic, Elena Rossi, stepped into Chef Amico. Her mission was to uncover the secret behind the restaurant's growing fame. She was greeted by Amico himself, whose eyes sparkled with the joy of a man who loved his work.\\n\\nElena was led to a table adorned with a simple, elegant setting. The first course was Caponata, a melody of eggplant, capers, and sweet tomatoes, which danced on her palate. Next came the Risotto al Nero di Seppia, a dish that told the tale of Sicily√¢‚Ç¨‚Ñ¢s love affair with the sea. Each spoonful was a revelation, the rich flavors of squid ink harmonizing with the creamy rice.\\n\\nThe final masterpiece was Cannoli, the crown jewel of Sicilian desserts. As Elena savored the sweet ricotta filling, encased in a perfectly crisp shell, she realized that Chef Amico wasn√¢‚Ç¨‚Ñ¢t just about the food. It was about the stories, the traditions, and the heart poured into every dish.\\n\\nLeaving the restaurant, Elena knew her review would sing praises not just of the food, but of the soul of Chef Amico√¢‚Ç¨‚Äùa place where every dish was a journey through Sicily, and every bite, a taste of Amico√¢‚Ç¨‚Ñ¢s dream come true.\"),\n",
       " Document(metadata={'source': './data/founder.txt'}, page_content='In the heart of the old quarter of Palermo, amidst the bustling market stalls and the echoes of lively street life, Amico was born into a family where food was more than sustenance√¢‚Ç¨‚Äùit was the language of love. Raised in the warmth of his Nonna Lucia\\'s kitchen, young Amico was captivated by the symphony of flavors and aromas that danced in the air, a testament to his family√¢‚Ç¨‚Ñ¢s Sicilian heritage.\\n\\nAmico\\'s life was deeply entwined with the vibrant essence of Sicilian cuisine. In the rustic kitchen where his Nonna conjured culinary magic, Amico found his calling. These formative years, filled with the rhythmic chopping of fresh herbs and the sizzling of rich tomato sauces, laid the foundation of his passion for cooking.\\n\\nThe Journey to Chef Amico\\n\\nFrom a young age, Amico was immersed in the art of Sicilian cooking. His days were punctuated by visits to the bustling markets of Palermo, where he learned to choose the freshest fish from the Mediterranean and the ripest fruits kissed by the Sicilian sun. These experiences not only sharpened his culinary skills but also deepened his respect for the land and its bounty.\\n\\nAs he grew, so did his desire to explore beyond the shores of Sicily. Venturing through Italy, Amico worked alongside renowned chefs, each teaching him a new facet of Italian cuisine. From the rolling hills of Tuscany to the romantic canals of Venice, he absorbed the diverse regional flavors, techniques, and traditions that would later influence his unique culinary style.\\n\\nCreating Chef Amico√¢‚Ç¨‚Ñ¢s Restaurant\\n\\nReturning to Palermo with a vision, Amico opened the doors to \"Chef Amico,\" a restaurant that was a culmination of his travels and a tribute to his Sicilian roots. Nestled in a quaint corner of the city, the restaurant quickly gained fame for its authentic flavors and Amico√¢‚Ç¨‚Ñ¢s innovative twists on traditional recipes.\\n\\nAt Chef Amico, every dish told a story. The menu, a tapestry of Sicilian classics and modern Italian cuisine, reflected Amico√¢‚Ç¨‚Ñ¢s journey and his commitment to excellence. Patrons were not just diners; they were part of an extended family, welcomed with the same warmth and joy that Amico had experienced in his Nonna√¢‚Ç¨‚Ñ¢s kitchen.\\n\\nPhilosophy of Hospitality\\n\\nFor Amico, hospitality was an art form. He believed that a meal was a celebration, a moment to pause and relish life√¢‚Ç¨‚Ñ¢s simple pleasures. His restaurant was a haven where strangers became friends over plates of arancini and glasses of Nero d√¢‚Ç¨‚Ñ¢Avola. The atmosphere he fostered was one of comfort and camaraderie, a place where every guest left with a full stomach and a happy heart.\\n\\nContinuing the Legacy\\n\\nToday, Chef Amico stands as a landmark in Palermo, a testament to Amico√¢‚Ç¨‚Ñ¢s dedication and love for his craft. His spirit of generosity and passion for food extends beyond the restaurant√¢‚Ç¨‚Ñ¢s walls. He mentors young chefs, shares his knowledge at culinary workshops, and supports local farmers and producers.\\n\\nAmico√¢‚Ç¨‚Ñ¢s legacy is not just in the dishes he creates but in the community he nurtures. His story is a tribute to the power of food to connect us, to share our stories, and to celebrate the richness of life. Chef Amico is more than a restaurant; it\\'s a home, built on a lifetime of love, learning, and the flavors of Sicily.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATABASE_URL = \"postgresql+psycopg2://admin:admin@localhost:5432/vectordb\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "store = PGVector(\n",
    "    collection_name=\"vectordb\",\n",
    "    connection_string=DATABASE_URL,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "# il file food.txt √® un file contenente un tabella con le portarte e i loro prezzi\n",
    "# si tratta quindi di qualcosa che non vogliamo nel vector store\n",
    "loader1 = TextLoader(\"./data/restaurant.txt\")\n",
    "loader2 = TextLoader(\"./data/founder.txt\")\n",
    "\n",
    "docs1 = loader1.load()\n",
    "docs2 = loader2.load()\n",
    "\n",
    "docs = docs1 + docs2\n",
    "docs # 2 Document in un a lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd74361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=20)\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "store.add_documents(chunks)\n",
    "\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f046a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üîó Creazione Catena RAG\n",
    "\n",
    "### ‚ùóInput: dizionario con chiave `question`\n",
    "\n",
    "```python\n",
    "input = {\n",
    "  \"question\": \"Chi √® il proprietario del ristorante?\"\n",
    "}\n",
    "```\n",
    "\n",
    "* Usiamo `RunnableLambda` o `itemgetter(\"question\")` per estrarre la domanda\n",
    "* La domanda viene passata al retriever\n",
    "* Output: contesto rilevante\n",
    "* Costruzione prompt + parsing risposta finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebd057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0338bc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chef Amico'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\": \"Who is the owner of the restaurant?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5b028",
   "metadata": {},
   "source": [
    "Ora scriviamo l'integrazione con SQL. \n",
    "\n",
    "Ovvero vogliamo un LLM che generi query SQL per interrogare il database SQL.\n",
    "\n",
    "Per farlo dobbiamo definire un nuovo template per far si che il modello scriva una query SQL che risponda alla domanda dell'utente.\n",
    "\n",
    "Per questo dobbiamo fornire uno `schema` il quale fornisce alcune informazioni sul database all'LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649ac95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßÆ Query SQL Generate via LLM\n",
    "\n",
    "### üß† Prompt per generare SQL\n",
    "\n",
    "```text\n",
    "Given the following table schema:\n",
    "\n",
    "{{schema}}\n",
    "\n",
    "Write a SQL query that answers the user's question:\n",
    "\n",
    "{{question}}\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è Classe SQLDatabase di LangChain\n",
    "\n",
    "```python\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(db_url)\n",
    "```\n",
    "\n",
    "### üìö Funzione `get_schema()`\n",
    "\n",
    "Restituisce le informazioni sullo schema con:\n",
    "\n",
    "```python\n",
    "db.get_table_info()\n",
    "```\n",
    "\n",
    "> Usiamo il file `ingest_data.py` dove troviamo una classe DatabaseManager dove si collega al nostro database e usiamo il metodo `setup_database()` per creare la tabella `products` che matcha con la nostra tabella in `food.txt`.\n",
    "\n",
    "> Dopo aver creato la tabella vogliamo inserire i food items. Quindi utilizziamo la funzione open() per leggere tutte le righe del file dato in input, che nel nostro caso sar√† food.txt, poi iteriamo su queste righe (food_items). Per prima cosa sostituiamo il segno del dollaro con niente poich√® vogliamo un numero intero, poi creiamo la nostra query di inserimento. \n",
    "\n",
    "> Vogliamo quindi inserire nella tabella dei prodotti nome, prezzo, descrizione, categoria e conflitto (se gi√† esiste, non vogliamo fare nulla, vogliamo solo valori unici e non duplicati dei nostri prodotti)\n",
    "\n",
    "> Abbiamo anche una funzione di aiuto, query_and_print, che esegue una query sulla tabella dei prodotti per ottenere tutti gli atricoli della tabella per poi stamparli\n",
    "\n",
    "\n",
    "### üßæ Creazione tabella `products`\n",
    "\n",
    "```sql\n",
    "CREATE TABLE products (\n",
    "  id TEXT PRIMARY KEY,\n",
    "  name TEXT,\n",
    "  price INTEGER,\n",
    "  description TEXT,\n",
    "  category TEXT\n",
    ")\n",
    "```\n",
    "\n",
    "### ü•ó Popolamento tabella\n",
    "\n",
    "* Eseguire lo script `ingest_data.py` con il comando : \n",
    "\n",
    "```bash\n",
    "python ingest_data.py\n",
    "```\n",
    "\n",
    "* Lettura da `food.txt`\n",
    "* Rimozione `$` dal prezzo\n",
    "* Insert con ON CONFLICT DO NOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc2e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "CONNECTION_STRING = (\n",
    "    \"postgresql+psycopg2://admin:admin@localhost:5432/vectordb\"\n",
    ")\n",
    "\n",
    "# qui importiamo il database SQL \n",
    "# otteniamo l'istanza del nostro databse\n",
    "db = SQLDatabase.from_uri(CONNECTION_STRING)\n",
    "\n",
    "# definiamo la funzione per ottenere lo schema \n",
    "# fornisce le informazioni al nostro modello\n",
    "# tutte le informazioni sul nostro database e sulle tabelle saranno fornite \n",
    "# da questa funzione \n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "# funzione che esegue sul database la query \n",
    "# generata dal modello \n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31fb2deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE langchain_pg_collection (\n",
      "\tname VARCHAR, \n",
      "\tcmetadata JSON, \n",
      "\tuuid UUID NOT NULL, \n",
      "\tCONSTRAINT langchain_pg_collection_pkey PRIMARY KEY (uuid)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from langchain_pg_collection table:\n",
      "name\tcmetadata\tuuid\n",
      "vectordb\tNone\t5faee19e-7b0c-4f7f-af2e-6f78a0a58ac1\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE langchain_pg_embedding (\n",
      "\tcollection_id UUID, \n",
      "\tembedding VECTOR, \n",
      "\tdocument VARCHAR, \n",
      "\tcmetadata JSON, \n",
      "\tcustom_id VARCHAR, \n",
      "\tuuid UUID NOT NULL, \n",
      "\tCONSTRAINT langchain_pg_embedding_pkey PRIMARY KEY (uuid), \n",
      "\tCONSTRAINT langchain_pg_embedding_collection_id_fkey FOREIGN KEY(collection_id) REFERENCES langchain_pg_collection (uuid) ON DELETE CASCADE\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from langchain_pg_embedding table:\n",
      "collection_id\tembedding\tdocument\tcmetadata\tcustom_id\tuuid\n",
      "5faee19e-7b0c-4f7f-af2e-6f78a0a58ac1\t[ 0.00933818 -0.03014523  0.01771624 ...  0.00327658 -0.01188974\n",
      " -0.02337176]\tIn the charming streets of Palermo, tucked away in a quaint alley, stood Chef Amico, a restaurant th\t{'source': './data/restaurant.txt'}\tec81ecc0-62c0-4c39-8492-561a734656fe\t86ac4f87-53b1-4afc-9ff1-b855efdfb535\n",
      "5faee19e-7b0c-4f7f-af2e-6f78a0a58ac1\t[ 0.01146708 -0.01092072  0.00600014 ... -0.00371923 -0.00111166\n",
      " -0.04331424]\tand creativity, the restaurant was a mosaic of his life√¢‚Ç¨‚Ñ¢s journey through the flavors of Italy.\t{'source': './data/restaurant.txt'}\t7710641c-da78-414f-b683-12fce1f12ac0\t6e6b7b05-9655-4330-bc45-1abc28b4dfb7\n",
      "5faee19e-7b0c-4f7f-af2e-6f78a0a58ac1\t[ 0.02528249 -0.02024441  0.01348312 ... -0.00700465 -0.00344313\n",
      " -0.02788704]\tChef Amico√¢‚Ç¨‚Ñ¢s doors opened to a world where the aromas of garlic and olive oil were as welcoming as\t{'source': './data/restaurant.txt'}\t925ccb2b-130c-4b46-9582-14c91e40df2c\t766f3b2c-36b7-40f7-ba70-e417bb4b9145\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# diamo un'occhiata a come √® lo schema\n",
    "print(get_schema(\"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96ac12",
   "metadata": {},
   "source": [
    "Vediamo che abbiamo molte informazioni sulle tabelle del nostro database, che in realt√† non ci servono per fare la query sulla nostra tabelle dei `products`.\n",
    "\n",
    "C'√® un modo migliore per ottenere le info del db e tabella che ci interessa rispetto a quello proposto dalla documentazione di langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e97a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ci√≤ di cui abbiamo sono solo le informazioni sulla nostra tabella products\n",
    "def get_schema(_):\n",
    "    engine = create_engine(CONNECTION_STRING)\n",
    "\n",
    "    inspector = inspect(engine)\n",
    "\n",
    "    columns = inspector.get_columns(\"products\")\n",
    "\n",
    "    column_data = [\n",
    "        {\n",
    "            \"Column Name\": col[\"name\"],\n",
    "            \"Data Type\": str(col[\"type\"]),\n",
    "            \"Nullable\": \"Yes\" if col[\"nullable\"] else \"No\",\n",
    "            \"Default\": col[\"default\"] if col[\"default\"] else \"None\",\n",
    "            \"Autoincrement\": \"Yes\" if col[\"autoincrement\"] else \"No\"\n",
    "        }\n",
    "        for col in columns\n",
    "    ]\n",
    "\n",
    "\n",
    "    schema_output = tabulate(column_data, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "    formatted_schema = f\"Schema for 'products' table:\\n{schema_output}\"\n",
    "\n",
    "    return formatted_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efc8ddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for 'products' table:\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n",
      "| Column Name   | Data Type      | Nullable   | Default                              | Autoincrement   |\n",
      "+===============+================+============+======================================+=================+\n",
      "| id            | INTEGER        | No         | nextval('products_id_seq'::regclass) | Yes             |\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n",
      "| name          | VARCHAR(100)   | Yes        | None                                 | No              |\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n",
      "| price         | NUMERIC(10, 2) | Yes        | None                                 | No              |\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n",
      "| description   | TEXT           | Yes        | None                                 | No              |\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n",
      "| category      | VARCHAR(100)   | Yes        | None                                 | No              |\n",
      "+---------------+----------------+------------+--------------------------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print(get_schema(\"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0225441",
   "metadata": {},
   "source": [
    ".bind(stop=[\"\\nSQLResult:\"]) crea un nuovo Runnable, che quando eseguito chiamer√† il modello con il parametro stop=[\"\\nSQLResult:\"].\n",
    "\n",
    "\n",
    "Ora:\n",
    "\n",
    "```python\n",
    "llm_with_stop.invoke(\"Translate this to SQL: ...\") # con il .bind()\n",
    "```\n",
    "\n",
    "funzioner√† come se avessi fatto:\n",
    "\n",
    "```python\n",
    "llm.invoke(\"Translate this to SQL: ...\", stop=[\"\\nSQLResult:\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e1201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT name, price\\nFROM products\\nWHERE category = 'Dessert'\\nORDER BY price DESC\\nLIMIT 1;\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilizziamo tale schema per creare la nostra chain\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# utilizziamo un metodo definito (.bind()) che lega gli argomenti del runtime ai Runnable\n",
    "# qui leghiamo l'argomento stop al modello\n",
    "# quindi vogliamo impedire all'LLM di generare token dopo aver creato\n",
    "# la nostra query SQL, dato che vogliamo solo la query SQL e nient'altro\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"]) \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_response.invoke({\"question\": \"Whats the most expensive dessert you offer?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18b498",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Test: Generazione Query SQL\n",
    "\n",
    "### ‚ùì Domanda:\n",
    "\n",
    "> ‚ÄúQual √® il dessert pi√π costoso che offrite?‚Äù\n",
    "\n",
    "### ‚úÖ Output SQL generato:\n",
    "\n",
    "```sql\n",
    "SELECT name, MAX(price) AS max_price\n",
    "FROM products\n",
    "WHERE category = 'dessert';\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Usiamo la query generata per interrogare eil nostro database\n",
    "\n",
    "- Utilizziamo il metodo, run_query(), definito in precedenza passandogli la query generata dal modello.\n",
    "\n",
    "- Creiamo una nuova chain per ottenere una risposta definitiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3cac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def debug(input):\n",
    "    print(\"SQL Output: \", input[\"query\"])\n",
    "    return input\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x['query'])\n",
    "    )\n",
    "    | RunnableLambda(debug)\n",
    "    | prompt_response\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70442cc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üó£Ô∏è Traduzione della risposta in linguaggio naturale\n",
    "\n",
    "### ‚úÖ Esempio di risposta:\n",
    "\n",
    "> ‚ÄúIl dessert pi√π costoso che offriamo √® il panettone al prezzo di 15 dollari.‚Äù\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Catena finale composta da:\n",
    "\n",
    "1. **Assegnazione dello schema**\n",
    "2. **LLM che genera SQL**\n",
    "3. **Esecuzione della query**\n",
    "4. **Risposta naturale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output:  SELECT name, price \n",
      "FROM products \n",
      "WHERE category = 'dessert' \n",
      "ORDER BY price DESC \n",
      "LIMIT 1;\n",
      "The most expensive dessert we offer is the Panettone, priced at $15.00.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = sql_chain.invoke({\"question\": \"Whats the most expensive dessert you offer?\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef7d69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Warning\n",
    "\n",
    "* La pipeline √® vulnerabile a **SQL Injection** se non gestita con attenzione.\n",
    "* Manca ancora il **routing dinamico** (arriver√† nel prossimo modulo).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Output dimostrato\n",
    "\n",
    "> Domanda: ‚ÄúQual √® il dessert pi√π costoso?‚Äù\n",
    ">\n",
    "> Risposta: ‚ÄúIl panettone, al prezzo di 15 dollari.‚Äù"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
