{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e69332d",
   "metadata": {},
   "source": [
    "# üîç LLM-based Document Compression\n",
    "\n",
    "## üéØ Obiettivo\n",
    "\n",
    "Utilizzare un **LLM come filtro intelligente** per decidere **quali documenti recuperati sono davvero rilevanti** per rispondere a una domanda, riducendo cos√¨ il carico sul LLM nella fase finale di generazione.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Cos‚Äô√® un Document Compressor?\n",
    "\n",
    "Un **compressore** basato su LLM:\n",
    "\n",
    "* Valuta **uno a uno** i documenti recuperati\n",
    "* Verifica se il contenuto √® **utile, accurato, pertinente e completo** rispetto alla domanda\n",
    "* Ritorna `True` se il documento √® rilevante, altrimenti `False`\n",
    "\n",
    "üí° Questo approccio √® **pi√π sofisticato** del semplice Top-K o del reranking, perch√© valuta **la pertinenza semantica completa**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972b2fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "loader = DirectoryLoader(\"./data\", glob=\"**/*.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=120,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding_function)\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fc49f",
   "metadata": {},
   "source": [
    "## Prepariamo un prompt per far si che il modello valuti i documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b74bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "DOCUMENT_EVALUATOR_PROMPT = PromptTemplate(\n",
    "    input_variables = ['document', 'question'],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to evaluate the provided document to determine if it is suited to answer the given user question. Assess the document for its relevance to the question, the completeness of information, and the accuracy of the content.\n",
    "    \n",
    "    Original question: {question}\n",
    "    Document for Evaluation: {document}\n",
    "    Evaluation Result: <<'True' if the document is suited to answer the question, 'False' if it is not>>\n",
    "\n",
    "    Note: Conclude with a 'True' or 'False' based on your analysis of the document's relevance, copleteness, and accuracy in relation to the question.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37f1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo una lista di Document\n",
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"The owner is Guivanni\"),\n",
    "    Document(page_content=\"Pizza Salami costs 10$\"),\n",
    "    Document(page_content=\"We close the restaurant at 10p.m each day\")\n",
    "]\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "compression_chain = DOCUMENT_EVALUATOR_PROMPT | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e825c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Evaluation Result: True\\n\\nThe document clearly states that the owner of the restaurant is Guivanni, which directly addresses the user's question. It is relevant, complete, and accurate in providing the requested information.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_chain.invoke(\n",
    "    {\"question\": \"Who is the owner of the restaurant\", \"document\": documents[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fddd46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÅ Funzione dinamica: `evaluate_documents`\n",
    "\n",
    "```python\n",
    "def evaluate_documents(inputs):\n",
    "    question = inputs[\"question\"]\n",
    "    docs = inputs[\"documents\"]\n",
    "\n",
    "    results = []\n",
    "    for doc in docs:\n",
    "        response = compression_chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content\n",
    "        })\n",
    "        # Interpreta la stringa come booleano\n",
    "        is_relevant = response.strip().lower() == \"true\"\n",
    "        results.append(is_relevant)\n",
    "\n",
    "    # Filtro documenti\n",
    "    filtered_docs = [doc for doc, keep in zip(docs, results) if keep]\n",
    "    return {\"documents\": filtered_docs}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3c628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def evaluate_documents(input: dict):\n",
    "    documents = input.get(\"documents\", [])\n",
    "    question = input.get(\"question\")\n",
    "\n",
    "    DOCUMENT_EVALUATOR_PROMPT = PromptTemplate(\n",
    "    input_variables = ['document', 'question'],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to evaluate the provided document to determine if it is suited to answer the given user question. Assess the document for its relevance to the question, the completeness of information, and the accuracy of the content.\n",
    "    \n",
    "    Original question: {question}\n",
    "    Document for Evaluation: {document}\n",
    "    Evaluation Result: <<'True' if the document is suited to answer the question, 'False' if it is not>>\n",
    "\n",
    "    Note: Conclude with a 'True' or 'False' based on your analysis of the document's relevance, copleteness, and accuracy in relation to the question.\n",
    "    \"\"\"\n",
    "    )\n",
    "    model = ChatOpenAI()\n",
    "\n",
    "    compression_chain = DOCUMENT_EVALUATOR_PROMPT | model | StrOutputParser()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for document in documents:\n",
    "        evaluation_result = compression_chain.invoke(\n",
    "            {\"document\": document.page_content, \"question\": question}\n",
    "        )\n",
    "        result = bool(re.search(r\"\\btrue\\b\", evaluation_result.lower()))\n",
    "        print(result)\n",
    "\n",
    "        results.append(result) # avremo una lista di booleani\n",
    "\n",
    "    filtered_documents = [doc for doc, res in zip(documents, results) if res]\n",
    "\n",
    "    return filtered_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d50eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "[Document(metadata={}, page_content='The owner is Guivanni')]\n"
     ]
    }
   ],
   "source": [
    "_input = {\n",
    "    \"documents\": [\n",
    "        Document(page_content=\"The owner is Guivanni\"),\n",
    "        Document(page_content=\"Pizza Salami costs 10$\"),\n",
    "        Document(page_content=\"We close the restaurant at 10p.m each day\")\n",
    "    ],\n",
    "    \"question\": \"Who is the owner of the restaurant?\"\n",
    "}\n",
    "\n",
    "\n",
    "results = evaluate_documents(_input)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756d6df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Vantaggi del Document Compressor\n",
    "\n",
    "| ‚úÖ Vantaggi                                 | ‚ùå Limiti                         |\n",
    "| ------------------------------------------ | -------------------------------- |\n",
    "| Migliore precisione nel filtrare documenti | Pi√π costoso (chiama LLM n volte) |\n",
    "| Elimina documenti irrilevanti              | Lento su grandi volumi           |\n",
    "| Rileva contenuti non informativi           | Richiede prompt tuning           |\n",
    "\n",
    "---\n",
    "\n",
    "## üîö Conclusione\n",
    "\n",
    "La **compressione basata su LLM** √® un potente strumento per:\n",
    "\n",
    "* Migliorare l'efficienza e l'accuratezza di una pipeline RAG\n",
    "* Filtrare documenti inutili o fuorvianti\n",
    "* Ridurre il carico computazionale sulla fase di generazione\n",
    "\n",
    "üîú **Prossima lezione**: **Routing**: come indirizzare query diverse verso percorsi diversi nella pipeline usando agenti o template dinamici.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
